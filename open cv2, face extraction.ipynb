{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ce676a4",
   "metadata": {},
   "source": [
    "First we have import required moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7be632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89b59a",
   "metadata": {},
   "source": [
    "Using Trained model,(Already made model used addboost algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9eacf80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=cv2.CascadeClassifier(\"C:\\\\Users\\\\khara\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902fa4d",
   "metadata": {},
   "source": [
    "provide location of the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "16b6af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"D:\\pepole\\image1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a046d47",
   "metadata": {},
   "source": [
    "#suppoer BGR or color image  we convert into gary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1e8daeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('myimg',gray)\n",
    "cv2.waitKey(4000) # screen hold time\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "157aa043",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_face=model.detectMultiScale(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598ebeb",
   "metadata": {},
   "source": [
    "using loop for multiple images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1b74c6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 199 31 31\n",
      "13 20 32 32\n",
      "246 197 35 35\n",
      "10 200 32 32\n",
      "130 203 35 35\n",
      "187 16 38 38\n",
      "12 323 31 31\n",
      "127 326 31 31\n",
      "316 18 37 37\n",
      "133 12 38 38\n",
      "65 15 41 41\n",
      "66 196 41 41\n",
      "73 318 43 43\n",
      "133 79 33 33\n",
      "194 80 29 29\n",
      "82 83 28 28\n",
      "8 76 33 33\n",
      "312 73 42 42\n",
      "131 142 31 31\n",
      "194 143 30 30\n",
      "248 141 33 33\n",
      "237 302 63 63\n",
      "63 141 33 33\n",
      "75 144 32 32\n",
      "317 263 30 30\n",
      "129 265 31 31\n",
      "74 262 34 34\n",
      "251 260 38 38\n",
      "317 324 35 35\n",
      "188 323 41 41\n",
      "3 259 43 43\n"
     ]
    }
   ],
   "source": [
    "#for face in list_face:\n",
    "#    for i in face:\n",
    "\n",
    "\n",
    "for x,y,w,h in list_face:\n",
    "    print(x,y,w,h)\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,255),2)\n",
    "\n",
    "cv2.imshow('list_face',img)\n",
    "cv2.waitKey(4000) # screen hold time\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab61a1b",
   "metadata": {},
   "source": [
    "Above all line combined below also minSize/maxSize/min/Neighbors is the image limit itna hi hona chahiye , scaleFactore=1.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "13d801ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defdc836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=cv2.CascadeClassifier(\"C:\\\\Users\\\\khara\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_default.xml\")\n",
    "#haarcascade_frontalface_default\n",
    "img=cv2.imread(\"D:\\pepole\\image1.jpg\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "list_face=model.detectMultiScale(gray,minSize=(25,25),maxSize=(300,300),scaleFactor=1.1,minNeighbors=2)\n",
    "for x,y,w,h in list_face:\n",
    "    print(x,y,w,h)\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,255),2)\n",
    "\n",
    "cv2.imshow('list_face',img)\n",
    "cv2.waitKey(4000) # screen hold time\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d59209",
   "metadata": {},
   "source": [
    "Extract face into folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4389e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=cv2.CascadeClassifier(\"C:\\\\Users\\\\khara\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_default.xml\")\n",
    "#haarcascade_frontalface_default\n",
    "img=cv2.imread(\"D:\\pepole\\image1.jpg\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "list_face=model.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=2)\n",
    "count=0\n",
    "for x,y,w,h in list_face:\n",
    "    \n",
    "    print(x,y,w,h)\n",
    "    face=img[x:x+h,y:y+w]\n",
    "    count+=1\n",
    "    cv2.imwrite(f'd:/pred_imges/{count}.png',face)\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,255),2)\n",
    "\n",
    "cv2.imshow('list_face',img)\n",
    "cv2.waitKey(4000) # screen hold time\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f937193",
   "metadata": {},
   "source": [
    "User input code format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=cv2.CascadeClassifier(\"C:\\\\Users\\\\khara\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_default.xml\")\n",
    "path=input(\"Enter the path like:- D:\\pepole\\image1.jpg\")\n",
    "folder=input(\"Enter the foder name\" )\n",
    "import os\n",
    "import sys\n",
    "if(os.path.exists(folder)):\n",
    "    print(\"folder exist provide other name\")\n",
    "else:\n",
    "    os.mkdir(folder)\n",
    "img=cv2.imread(path)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "list_face=model.detectMultiScale(gray,scaleFactor=1.2)\n",
    "count=0\n",
    "for x,y,w,h in list_face:\n",
    "    face=img[x:x+w,y:y+h]\n",
    "    count+=1\n",
    "    cv2.imwrite(f\"{folder}/{count}.png\",face)\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "cv2.imshow('list_face',img)\n",
    "cv2.waitKey(4000) # screen hold time\n",
    "cv2.destroyAllWindows()\n",
    "print(count,\"faces extracted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
